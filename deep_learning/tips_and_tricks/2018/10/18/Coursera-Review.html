<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Coursera DL Specialization Review | Random Thoughts</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Coursera DL Specialization Review" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Tips and tricks from Andrew Ng’s Coursera DL Specialization" />
<meta property="og:description" content="Tips and tricks from Andrew Ng’s Coursera DL Specialization" />
<link rel="canonical" href="https://krisztiankovacs.com/blog/deep_learning/tips_and_tricks/2018/10/18/Coursera-Review.html" />
<meta property="og:url" content="https://krisztiankovacs.com/blog/deep_learning/tips_and_tricks/2018/10/18/Coursera-Review.html" />
<meta property="og:site_name" content="Random Thoughts" />
<meta property="og:image" content="https://krisztiankovacs.com/blog/images/dl_certificate_small.jpg" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2018-10-18T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://krisztiankovacs.com/blog/deep_learning/tips_and_tricks/2018/10/18/Coursera-Review.html","@type":"BlogPosting","headline":"Coursera DL Specialization Review","dateModified":"2018-10-18T00:00:00-05:00","datePublished":"2018-10-18T00:00:00-05:00","image":"https://krisztiankovacs.com/blog/images/dl_certificate_small.jpg","mainEntityOfPage":{"@type":"WebPage","@id":"https://krisztiankovacs.com/blog/deep_learning/tips_and_tricks/2018/10/18/Coursera-Review.html"},"description":"Tips and tricks from Andrew Ng’s Coursera DL Specialization","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://krisztiankovacs.com/blog/feed.xml" title="Random Thoughts" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-125087891-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-125087891-1');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/blog/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Random Thoughts</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Coursera DL Specialization Review</h1><p class="page-description">Tips and tricks from Andrew Ng's Coursera DL Specialization</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2018-10-18T00:00:00-05:00" itemprop="datePublished">
        Oct 18, 2018
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      7 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/blog/categories/#deep_learning">deep_learning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/blog/categories/#tips_and_tricks">tips_and_tricks</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#overview">Overview</a></li>
<li class="toc-entry toc-h2"><a href="#random-search-beats-grid-search">Random Search beats Grid Search</a></li>
<li class="toc-entry toc-h2"><a href="#multiple-minima-are-not-an-issue-in-deep-learning">Multiple minima are not an issue in deep learning</a></li>
<li class="toc-entry toc-h2"><a href="#dont-use-rank-1-arrays">Don’t use rank 1 arrays</a></li>
<li class="toc-entry toc-h2"><a href="#build-something-quickly-iterate-fast">Build something quickly, iterate fast</a></li>
<li class="toc-entry toc-h2"><a href="#changing-proportions-of-traindevtest-sets-for-big-data">Changing proportions of train/dev/test sets for big data</a></li>
<li class="toc-entry toc-h2"><a href="#human-error-helping-with-biasvariance">Human error helping with bias/variance</a></li>
<li class="toc-entry toc-h2"><a href="#incorrectly-labelled-training-examples">Incorrectly labelled training examples</a></li>
<li class="toc-entry toc-h2"><a href="#what-to-do-if-traindev-sets-have-different-distributions">What to do if train/dev sets have different distributions</a></li>
<li class="toc-entry toc-h2"><a href="#few-shot-learning-with-siamese-network">Few shot learning with Siamese network</a></li>
<li class="toc-entry toc-h2"><a href="#word-embeddings-dont-need-a-complex-model">Word embeddings don’t need a complex model</a></li>
</ul><h2 id="overview">
<a class="anchor" href="#overview" aria-hidden="true"><span class="octicon octicon-link"></span></a>Overview</h2>

<p>Besides <a href="course.fast.ai">fastai</a>, Andrew Ng’s Coursera’s DL specialization is definitely the resource I recommend to get started with deep learning. The course teaches both basic DL theory, and tips and tricks on how to optimize your workflow. The lectures are really easy to understand and follow (great), and the coding assignments are also extremely simple (not so great). Coursera says that the course takes between 4-5 months to complete, but if you’re dedicated you can do it in less than a month.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center"><img style="float: center;" src="/blog/images/dl_certificate.jpg" width="400"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><em>You’ll get a pretty certificate when you’re done.</em></td>
    </tr>
  </tbody>
</table>

<p>I went through the course in 2018, when I decided to give deep learning a shot. Here are my favourite snippets from the time:</p>

<h2 id="random-search-beats-grid-search">
<a class="anchor" href="#random-search-beats-grid-search" aria-hidden="true"><span class="octicon octicon-link"></span></a>Random Search beats Grid Search</h2>

<p>We often have to optimize multiple hyperparameters. For example, suppose you have a standard feed-forward neural net, with 1 hidden layer. You are trying to decide on the number of hidden units, and the amount of dropout. You have resources to fit multiple models, and compare their results on your validation set.</p>

<p>One way to search the hyperparameter space is grid-search: run all combinations of a discrete subset of parameters. For example, you might consider a network with 50, 100, 150, and 200 hidden units; and dropout rates of 0.1, 0.2, … 0.5. Take all combinations of these values, and you get 20 different settings to run your network with.</p>

<p>Or you can just take 20 random samples from relevant parameter range: 50-200 for hidden units, and 0.1-0.5 for dropout.</p>

<p>Why is the second approach better? Because not all hyperparameters have the same impact. Suppose that in this case dropout doesn’t make a big difference, but the number of hidden units matters. With grid-search, you have 20 runs, but only sample 4 distinct values of the parameter that matters. With random search, you take 20 samples for the number of hidden units as well.</p>

<p>This effect gets even more pronounced in higher dimensions. The number of runs required for grid-search explodes. Why waste runtime on parameters that might not even matter?</p>

<h2 id="multiple-minima-are-not-an-issue-in-deep-learning">
<a class="anchor" href="#multiple-minima-are-not-an-issue-in-deep-learning" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multiple minima are not an issue in deep learning</h2>

<p>We often illustrate gradient descent with a 2 dimensional picture. In two dimensions it’s easy to picture a curve with multiple minima where gradient descent (or any other optimization algorithm) finds a sub-optimal local minima. This intuition doesn’t carry over to higher dimensions.</p>

<p>Two have a local minimum, your directional derivative has to be 0 in all directions. In very high dimensions, the probability that happens is fairly small. If you find a local minimum, chances are you hit the global one.</p>

<p>However, your surface will be full of (relatively) flat areas and saddle points (where your gradient is 0 in some directions, but not all). Flat surfaces and saddle points are problematic because they make your update steps tiny, and your optimization algorithm may not find a minimum in a reasonable amount of time.</p>

<p><strong><em>2020 Update:</em></strong> <em>this idea is probably false. The current understanding is that deep networks have, indeed, multiple minima, but for mysterious reasons they tend to have similar performance.</em></p>

<h2 id="dont-use-rank-1-arrays">
<a class="anchor" href="#dont-use-rank-1-arrays" aria-hidden="true"><span class="octicon octicon-link"></span></a>Don’t use rank 1 arrays</h2>

<p>If you sum an (n, n) matrix in numpy, the result is a (n,) rank 1 array. This result can lead to bugs (what if you summed over the wrong axis?), and makes broadcasting unclear. It’s better to avoid these rank 1 arrays for clarity.</p>

<p>Instead, we should sum to a (n, 1) or (1, n) vector. That makes it explicit over which dimension we are summing. We just need to use the option ‘keepdims = True’.</p>

<p>Also, we should pepper our code with assertions that check the shape of our arrays. (Putting ‘assert W.shape = (x, y)’ into our code). The computational overhead is minimal, and the assertions help us find errors quickly.</p>

<h2 id="build-something-quickly-iterate-fast">
<a class="anchor" href="#build-something-quickly-iterate-fast" aria-hidden="true"><span class="octicon octicon-link"></span></a>Build something quickly, iterate fast</h2>

<p>Andrew’s recurring suggestion is to quickly iterate. Instead of trying to build a hyper-complex model from scratch, build a simple one, then look at where the largest margins of improvement are.</p>

<p>To facilitate quick iteration, a single number evaluation metric is extremely helpful. It’s hard to iterate if we have multiple metrics, each preferring a different model. To deal with multiple metrics we have two strategies.</p>

<p>First, we can combine them. For example, we can turn precision and recall into an f1 (or f2) score.</p>

<p>Alternatively, we can designate satisficing metrics. Satisficing metrics only have to be over (or under) a certain threshold. For example, we might say that the memory requirement our model is a satisficing metric. We want our model to fit into memory, but after that we don’t care about its size. We would have our optimizing metric, say the f1 score, with the constraint that our model fits into memory.</p>

<h2 id="changing-proportions-of-traindevtest-sets-for-big-data">
<a class="anchor" href="#changing-proportions-of-traindevtest-sets-for-big-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Changing proportions of train/dev/test sets for big data</h2>

<p>60/20/20 was a typical train/validation/test split proportion for machine learning in the pre-deep-learning era. However, with tens of millions of examples, this split doesn’t make sense anymore. After all, the validation set is only used for monitoring performance and optimizing hyper-parameters, and the test set only serves to calculate our error. Often, 1% of our data is enough for them.</p>

<h2 id="human-error-helping-with-biasvariance">
<a class="anchor" href="#human-error-helping-with-biasvariance" aria-hidden="true"><span class="octicon octicon-link"></span></a>Human error helping with bias/variance</h2>

<p>For many deep learning tasks it is helpful to know, at least approximately, what human error is. For naturally occurring tasks, such as image classification, human error is plausibly close <a href="https://en.wikipedia.org/wiki/Bayes_error_rate">Bayes optimal error</a>. Knowing human/Bayes error we know how much our model can to improve.</p>

<p>Moreover, knowing human error helps us determine if our algorithm suffers from high bias. We normally treat the training set error as a measure of our algorithm’s bias, and the difference between our trianing and validation error as the algorithms variance.</p>

<p>That’s not fair though, as some of the training set error might be unavoidable. For example, when doing image classification, some of our training examples might be mislabeled. Even a perfect model would have training set error.</p>

<p>Instead, we should focus on the avoidable bias. Knowing human error comes in handy here. If our model has a 2% training error on an image classification task, but humans also have a 2% error (maybe because of mislabeled examples), we know that reducing bias is not the best margin for improvement. However, if humans have a ~0% error, it is worth trying bias reducing techniques.</p>

<h2 id="incorrectly-labelled-training-examples">
<a class="anchor" href="#incorrectly-labelled-training-examples" aria-hidden="true"><span class="octicon octicon-link"></span></a>Incorrectly labelled training examples</h2>

<p>Not necessarily a problem, as long as there aren’t too many of them, and the mislabelling isn’t systematic.</p>

<h2 id="what-to-do-if-traindev-sets-have-different-distributions">
<a class="anchor" href="#what-to-do-if-traindev-sets-have-different-distributions" aria-hidden="true"><span class="octicon octicon-link"></span></a>What to do if train/dev sets have different distributions</h2>

<p>Validation and test sets should always have the same distributions, but sometimes our training set can have a different one.</p>

<p>For example, suppose we are building an app that classifies pictures into cats vs. non-cats. Our app will be used for images recorded on a smartphone. We have 10000 such images that we can split into a validation and test set.</p>

<p>Our training set is slightly different. We have 1 million pictures downloaded from the internet. These aren’t exactly the same as the ones recorded on the phone: they might be higher resolution, the cat is usually in the middle, etc. But we have a lot more of them.</p>

<p>We fit a model. It has 2% training error, but the error on our validation set is a whopping 8%. Does our model suffer from high variance, or is it just our training and validation sets being different?</p>

<p>To answer this question, we can create a separate ‘train-dev’ set. This is data of the same distribution as our training set that isn’t used for training.</p>

<p>In our example, we would set aside a subset of the 1 million images from the internet. We use the rest for training. Now we can compare errors.</p>

<p>If our model has a 8% error on this train-dev set, we know that it suffers from high variance. We could try variance reducing techniques, such as increasing regularization. On the other hand, if it scores 2% on the train-dev set (same as the training error), we know that the problem is the differing distributions for training and validation. We need to collect more mobile phone data so we can train our model on that.</p>

<h2 id="few-shot-learning-with-siamese-network">
<a class="anchor" href="#few-shot-learning-with-siamese-network" aria-hidden="true"><span class="octicon octicon-link"></span></a>Few shot learning with Siamese network</h2>

<p>Siamese networks look <a href="https://www.quora.com/What-are-Siamese-neural-networks-what-applications-are-they-good-for-and-why">awesome</a>.</p>

<h2 id="word-embeddings-dont-need-a-complex-model">
<a class="anchor" href="#word-embeddings-dont-need-a-complex-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word embeddings don’t need a complex model</h2>

<p>A simple model like skip-grams suffices. To learn embeddings in an efficient way (avoiding the massive computations needed for a softmax classifier) we can use algorithms such as negative sampling or Glove.</p>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="kk1694/blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/blog/deep_learning/tips_and_tricks/2018/10/18/Coursera-Review.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>Trying to teach computers to learn</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/kk1694" title="kk1694"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/kk1694" title="kk1694"><svg class="svg-icon grey"><use xlink:href="/blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
